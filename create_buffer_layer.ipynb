{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 11:27:00.067476: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 11:27:00.987228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# create a custom layer witch have a buffer to store the weights and informationb throw the training\n",
    "\n",
    "class DenseBuffer(layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(DenseBuffer, self).__init__()\n",
    "        self.buffer = None #the buffer is the res of the layer\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        self.buffer_iterator = 0 #the iterator to iterate over the buffer\n",
    "        #create an iteraor to iterate over the buffer\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        w_init = tf.random_normal_initializer()\n",
    "\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_shape[-1], self.units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(self.units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "        #create the buffer\n",
    "        self.buffer = tf.Variable(\n",
    "            initial_value=tf.zeros(shape=(1, self.units), dtype=\"float32\"),\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.buffer_iterator == 0:\n",
    "            #if the buffer is empty, just add the res of the layer\n",
    "            res = tf.matmul(inputs, self.w) + self.b\n",
    "            self.buffer = res\n",
    "            self.buffer_iterator += 1\n",
    "            return res\n",
    "        else:\n",
    "            #if the buffer is not empty, add the res of the layer to the buffer\n",
    "            res = tf.matmul(tf.matmul(inputs, self.w) + self.b, self.buffer)\n",
    "            self.buffer = res\n",
    "            self.buffer_iterator += 1\n",
    "            return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test = DenseBuffer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 11:27:02.245695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:02.274272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:02.274324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:02.276709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:02.276760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:02.276796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:03.012370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:03.012473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:03.012484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-09 11:27:03.012521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-09 11:27:03.012552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7335 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-04-09 11:27:04.422373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\narray([[ 0.00844032, -0.00092541, -0.00511014, -0.16888063, -0.08427596,\n        -0.21597949, -0.01732077,  0.01453283, -0.02193583, -0.10942151,\n         0.1308423 , -0.06047181, -0.2800917 , -0.00221445,  0.0289262 ,\n        -0.1397514 ,  0.09553465,  0.05442366,  0.0678086 ,  0.13387525,\n        -0.01041169,  0.0281101 ,  0.06670436, -0.09726016, -0.14215322,\n        -0.20824023, -0.02130379,  0.09637992, -0.11698732, -0.08628592,\n        -0.00962289, -0.11411408]], dtype=float32)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(tf.constant([[1, 2]], dtype=tf.float32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
