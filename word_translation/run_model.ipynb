{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:00:59.229551700Z",
     "start_time": "2023-05-07T14:00:57.147780800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:00:57.381335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-07 16:00:58.033101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "tqdm.pandas()\n",
    "# keras set seed\n",
    "utils.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load the data\n",
    "DATA_FOLDER = \"/mnt/d/sign-lang-data/\"\n",
    "train = pd.read_csv(os.path.join(DATA_FOLDER, \"train.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:00:59.314684200Z",
     "start_time": "2023-05-07T14:00:59.232551900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "s_train = train.sample(2000)\n",
    "dict_sign = {}\n",
    "for i, sign in enumerate(s_train[\"sign\"].unique()):\n",
    "    dict_sign[sign] = i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:00:59.321684100Z",
     "start_time": "2023-05-07T14:00:59.318684100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                path  participant_id   \n77681  train_landmark_files/49445/4179379151.parquet           49445  \\\n32268   train_landmark_files/2044/2321535930.parquet            2044   \n73619  train_landmark_files/16069/4015771323.parquet           16069   \n92262   train_landmark_files/32319/908757938.parquet           32319   \n94183   train_landmark_files/29302/987765989.parquet           29302   \n...                                              ...             ...   \n77415   train_landmark_files/27610/416789928.parquet           27610   \n32027  train_landmark_files/29302/2311259378.parquet           29302   \n74394    train_landmark_files/4718/404775947.parquet            4718   \n58468  train_landmark_files/30680/3392431752.parquet           30680   \n82      train_landmark_files/26734/100328364.parquet           26734   \n\n       sequence_id      sign  \n77681   4179379151    puzzle  \n32268   2321535930      talk  \n73619   4015771323     chair  \n92262    908757938      food  \n94183    987765989       pen  \n...            ...       ...  \n77415    416789928      wait  \n32027   2311259378       pig  \n74394    404775947      stay  \n58468   3392431752       man  \n82       100328364  scissors  \n\n[2000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>77681</th>\n      <td>train_landmark_files/49445/4179379151.parquet</td>\n      <td>49445</td>\n      <td>4179379151</td>\n      <td>puzzle</td>\n    </tr>\n    <tr>\n      <th>32268</th>\n      <td>train_landmark_files/2044/2321535930.parquet</td>\n      <td>2044</td>\n      <td>2321535930</td>\n      <td>talk</td>\n    </tr>\n    <tr>\n      <th>73619</th>\n      <td>train_landmark_files/16069/4015771323.parquet</td>\n      <td>16069</td>\n      <td>4015771323</td>\n      <td>chair</td>\n    </tr>\n    <tr>\n      <th>92262</th>\n      <td>train_landmark_files/32319/908757938.parquet</td>\n      <td>32319</td>\n      <td>908757938</td>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>94183</th>\n      <td>train_landmark_files/29302/987765989.parquet</td>\n      <td>29302</td>\n      <td>987765989</td>\n      <td>pen</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>77415</th>\n      <td>train_landmark_files/27610/416789928.parquet</td>\n      <td>27610</td>\n      <td>416789928</td>\n      <td>wait</td>\n    </tr>\n    <tr>\n      <th>32027</th>\n      <td>train_landmark_files/29302/2311259378.parquet</td>\n      <td>29302</td>\n      <td>2311259378</td>\n      <td>pig</td>\n    </tr>\n    <tr>\n      <th>74394</th>\n      <td>train_landmark_files/4718/404775947.parquet</td>\n      <td>4718</td>\n      <td>404775947</td>\n      <td>stay</td>\n    </tr>\n    <tr>\n      <th>58468</th>\n      <td>train_landmark_files/30680/3392431752.parquet</td>\n      <td>30680</td>\n      <td>3392431752</td>\n      <td>man</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>train_landmark_files/26734/100328364.parquet</td>\n      <td>26734</td>\n      <td>100328364</td>\n      <td>scissors</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:00:59.333191500Z",
     "start_time": "2023-05-07T14:00:59.322684100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "max_nb_frames = 100\n",
    "def preprocess(parquet_path):\n",
    "    df = pd.read_parquet(os.path.join(DATA_FOLDER,parquet_path), engine=\"pyarrow\", columns=[\"frame\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    # create a sequence as a list of frames (each frame is a np.array)\n",
    "    frames = []\n",
    "    for name, timestep in df.groupby(\"frame\"):\n",
    "        frame = np.stack(timestep[[\"x\", \"y\", \"z\"]].values)\n",
    "        frames.append(frame)\n",
    "\n",
    "    sequence = np.reshape(np.stack(frames), (len(frames),1629))\n",
    "\n",
    "    if len(sequence) > max_nb_frames:\n",
    "        sequence = sequence[:max_nb_frames]\n",
    "    else:\n",
    "        sequence = np.concatenate((sequence, np.zeros((max_nb_frames - len(sequence), 1629))))\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\"\"\"def get_label(sequence, sign, dict_):\n",
    "    labels = []\n",
    "    for i in range(len(sequence)):\n",
    "        labels.append(utils.to_categorical(dict_[sign], num_classes=len(s_train[\"sign\"].unique())))\n",
    "    return np.stack(labels)\"\"\"\n",
    "\n",
    "def get_label(sequence, sign, dict_):\n",
    "    return utils.to_categorical(dict_[sign], num_classes=len(s_train[\"sign\"].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:00:59.354701900Z",
     "start_time": "2023-05-07T14:00:59.338191400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e5d83d67421474b8ce84dea86fbfd55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab0da6905b714dddaaab843a81612643"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "# X\n",
    "s_train[\"sequence\"] = s_train[\"path\"].progress_apply(preprocess)\n",
    "# Y\n",
    "# get max length of sequence\n",
    "#max_length = s_train[\"sequence\"].progress_apply(lambda x: len(x)).max()\n",
    "# complete the sequence with zeros\n",
    "#s_train[\"sequence\"] = s_train[\"sequence\"].progress_apply(lambda x: np.concatenate((x, np.zeros((max_length - len(x), 1629)))))\n",
    "\n",
    "s_train[\"label\"] = s_train.progress_apply(lambda x: get_label(x[\"sequence\"], x[\"sign\"], dict_sign), axis=1)\n",
    "#s_train[\"label\"] =\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:02:11.842431300Z",
     "start_time": "2023-05-07T14:00:59.341191600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:02:12.104263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:12.238132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:12.238222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:12.244654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:12.244722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:12.244764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:13.289456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:13.289840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:13.289861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-07 16:02:13.289968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-07 16:02:13.290314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7335 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dense, LSTM, Masking\n",
    "# Inisialize the model from custom class\n",
    "from custom_model.first import CustomModel\n",
    "batch_size = 10\n",
    "timesteps = 100\n",
    "features = 1629\n",
    "nb_classes = len(s_train[\"sign\"].unique())\n",
    "\n",
    "model = CustomModel(batch_size, timesteps, features, nb_classes)\n",
    "# model = CustomModel( input_layer, output_layer)\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['categorical_accuracy'], sample_weight_mode='temporal')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:02:14.033781800Z",
     "start_time": "2023-05-07T14:02:11.842431300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "x_train = np.stack(s_train[\"sequence\"].values)\n",
    "y_train = np.stack(s_train[\"label\"].values)\n",
    "del s_train\n",
    "del train\n",
    "del dict_sign\n",
    "# do split with sklearn\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "del x_train\n",
    "del y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T14:02:16.517227900Z",
     "start_time": "2023-05-07T14:02:14.032776200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:02:16.760880: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1042560000 exceeds 10% of free system memory.\n",
      "2023-05-07 16:02:17.474316: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1042560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:02:20.781589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-07 16:02:20.980380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-07 16:02:21.527804: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f67a7748550 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-07 16:02:21.527859: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-05-07 16:02:21.698989: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-07 16:02:21.825173: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 8s 25ms/step - loss: 5.5401 - categorical_accuracy: 0.0044 - val_loss: 5.5235 - val_categorical_accuracy: 0.0050\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.5216 - categorical_accuracy: 0.0081 - val_loss: 5.5234 - val_categorical_accuracy: 0.0075\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.5090 - categorical_accuracy: 0.0075 - val_loss: 5.5314 - val_categorical_accuracy: 0.0075\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.5005 - categorical_accuracy: 0.0075 - val_loss: 5.5299 - val_categorical_accuracy: 0.0075\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 5.4913 - categorical_accuracy: 0.0050 - val_loss: 5.5337 - val_categorical_accuracy: 0.0075\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4846 - categorical_accuracy: 0.0088 - val_loss: 5.5390 - val_categorical_accuracy: 0.0075\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4772 - categorical_accuracy: 0.0063 - val_loss: 5.5452 - val_categorical_accuracy: 0.0075\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4700 - categorical_accuracy: 0.0075 - val_loss: 5.5497 - val_categorical_accuracy: 0.0050\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4636 - categorical_accuracy: 0.0100 - val_loss: 5.5558 - val_categorical_accuracy: 0.0075\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4567 - categorical_accuracy: 0.0088 - val_loss: 5.5631 - val_categorical_accuracy: 0.0075\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4498 - categorical_accuracy: 0.0094 - val_loss: 5.5737 - val_categorical_accuracy: 0.0050\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 5.4442 - categorical_accuracy: 0.0094 - val_loss: 5.5769 - val_categorical_accuracy: 0.0050\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4376 - categorical_accuracy: 0.0113 - val_loss: 5.5851 - val_categorical_accuracy: 0.0050\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4332 - categorical_accuracy: 0.0094 - val_loss: 5.5874 - val_categorical_accuracy: 0.0025\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4278 - categorical_accuracy: 0.0131 - val_loss: 5.5938 - val_categorical_accuracy: 0.0075\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4256 - categorical_accuracy: 0.0094 - val_loss: 5.6063 - val_categorical_accuracy: 0.0050\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4187 - categorical_accuracy: 0.0069 - val_loss: 5.6159 - val_categorical_accuracy: 0.0050\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.4132 - categorical_accuracy: 0.0162 - val_loss: 5.6239 - val_categorical_accuracy: 0.0075\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 2s 16ms/step - loss: 5.4051 - categorical_accuracy: 0.0113 - val_loss: 5.6225 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 2s 16ms/step - loss: 5.4070 - categorical_accuracy: 0.0125 - val_loss: 5.6306 - val_categorical_accuracy: 0.0100\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 2s 16ms/step - loss: 5.3950 - categorical_accuracy: 0.0137 - val_loss: 5.6426 - val_categorical_accuracy: 0.0050\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 5.3918 - categorical_accuracy: 0.0113 - val_loss: 5.6540 - val_categorical_accuracy: 0.0025\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 5.3845 - categorical_accuracy: 0.0144 - val_loss: 5.6569 - val_categorical_accuracy: 0.0050\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 3s 18ms/step - loss: 5.3776 - categorical_accuracy: 0.0150 - val_loss: 5.6598 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      " 34/160 [=====>........................] - ETA: 1s - loss: 5.3463 - categorical_accuracy: 0.0206"
     ]
    }
   ],
   "source": [
    "metrics = model.fit(X_train, Y_train , validation_data=(X_test, Y_test), epochs=100, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:02:16.521223100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the metrics\n",
    "plt.plot(metrics.history['categorical_accuracy'])\n",
    "plt.plot(metrics.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(metrics.history['loss'])\n",
    "plt.plot(metrics.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
