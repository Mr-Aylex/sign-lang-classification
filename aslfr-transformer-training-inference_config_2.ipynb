{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Hello Fellow Kagglers,\n",
    "\n",
    "This competition has been challenging to say the least, especially the submission.\n",
    "\n",
    "After a few weeks I finally got a working training + inference pipeline which is shared through this notebook.\n",
    "\n",
    "The model consists of a transformer embedding + encoder + decoder.\n",
    "\n",
    "Inference is performed by starting with an SOS token and predicting one character at a time using the previous prediction.\n",
    "\n",
    "Feel free to ask for clarafications or comment.\n",
    "\n",
    "Notebook will be updated periodically.\n",
    "\n",
    "[Preprocessing Notebook](https://www.kaggle.com/code/markwijkhuizen/aslfr-eda-preprocessing-dataset)\n",
    "\n",
    "**V6**\n",
    "\n",
    "This competition has an inference limit of 5 hours which requires careful allocation of computational resources in the model. Most changes are based on the assymetrical number of encoder/deocder calls during inference.\n",
    "\n",
    "Inference requires the encoder to encode the input frames and subsequently use that encoding to predict the 1st character by inputting the encoding and SOS (Start of Sentence) token. Next, the encoding, SOS token and 1st predicted token are used to predict the 2nd character. Inference thus requires 1 call to the encoder and multiple calls to the encoder. On average a phrase is 18 characters long, requiring 18+1(SOS token) calls to the decoder. To stay within the 5 hour inference limit the encoder can be computationally heavy, however the decoder should be light.\n",
    "\n",
    "Some inspiration is taken from the [1st place solution - training](https://www.kaggle.com/code/hoyso48/1st-place-solution-training) from the last [Google - Isolated Sign Language Recognition\n",
    "](https://www.kaggle.com/competitions/asl-signs) competition.\n",
    "\n",
    "* Increased training epochs 30 -> 100\n",
    "* Using all data for training, no validation set\n",
    "* Increased number of decoder blocks 2 -> 3\n",
    "* Increased encoder dimensions 256 -> 384\n",
    "* Halved attention dimension to decrease computational intensity of Multi Head Attention\n",
    "* Added 20% dropout to multi head attention output\n",
    "* Batch size 128 -> 64\n",
    "* Classification layer linear activation for logits in loss function\n",
    "\n",
    "**Helpful Tutorials**\n",
    "\n",
    "[English-to-Spanish translation with a sequence-to-sequence Transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)\n",
    "\n",
    "[Lecture 12.1 Self-attention](https://www.youtube.com/watch?v=KmAISyVvE1Y&list=LL&index=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from leven import levenshtein\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import time\n",
    "import json\n",
    "\n",
    "# TQDM Progress Bar With Pandas Apply Function\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f'Tensorflow Version {tf.__version__}')\n",
    "print(f'Python Version: {sys.version}')\n",
    "\n",
    "DATA_FOLDER = \"/mnt/e/sign-lang-data-2\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:38.424125Z",
     "iopub.execute_input": "2023-07-06T19:48:38.424554Z",
     "iopub.status.idle": "2023-07-06T19:48:43.875924Z",
     "shell.execute_reply.started": "2023-07-06T19:48:38.424505Z",
     "shell.execute_reply": "2023-07-06T19:48:43.874907Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Character 2 Ordinal Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Read Character to Ordinal Encoding Mapping\n",
    "with open(f'{DATA_FOLDER}/character_to_prediction_index.json') as json_file:\n",
    "    CHAR2ORD = json.load(json_file)\n",
    "    \n",
    "# Ordinal to Character Mapping\n",
    "ORD2CHAR = {j:i for i,j in CHAR2ORD.items()}\n",
    "    \n",
    "# Character to Ordinal Encoding Mapping   \n",
    "display(pd.Series(CHAR2ORD).to_frame('Ordinal Encoding'))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:43.881876Z",
     "iopub.execute_input": "2023-07-06T19:48:43.882517Z",
     "iopub.status.idle": "2023-07-06T19:48:43.904538Z",
     "shell.execute_reply.started": "2023-07-06T19:48:43.882482Z",
     "shell.execute_reply": "2023-07-06T19:48:43.903479Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# If Notebook Is Run By Committing or In Interactive Mode For Development\n",
    "IS_INTERACTIVE = False#os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "# Verbose Setting during training\n",
    "VERBOSE = 2 if IS_INTERACTIVE else 2\n",
    "# Global Random Seed\n",
    "SEED = 42\n",
    "# Number of Frames to resize recording to\n",
    "N_TARGET_FRAMES = 128\n",
    "# Global debug flag, takes subset of train\n",
    "DEBUG = False\n",
    "# Number of Unique Characters To Predict + Pad Token + SOS Token + EOS Token\n",
    "N_UNIQUE_CHARACTERS0 = len(CHAR2ORD)\n",
    "N_UNIQUE_CHARACTERS = len(CHAR2ORD) + 1 + 1 + 1\n",
    "PAD_TOKEN = len(CHAR2ORD) # Padding\n",
    "SOS_TOKEN = len(CHAR2ORD) + 1 # Start Of Sentence\n",
    "EOS_TOKEN = len(CHAR2ORD) + 2 # End Of Sentence\n",
    "# Whether to use 10% of data for validation\n",
    "USE_VAL = True\n",
    "# Batch Size\n",
    "BATCH_SIZE = 64\n",
    "# Number of Epochs to Train for\n",
    "N_EPOCHS = 2 if IS_INTERACTIVE else 100\n",
    "# Number of Warmup Epochs in Learning Rate Scheduler\n",
    "N_WARMUP_EPOCHS = 10\n",
    "# Maximum Learning Rate\n",
    "LR_MAX = 1e-3\n",
    "# Weight Decay Ratio as Ratio of Learning Rate\n",
    "WD_RATIO = 0.05\n",
    "# Length of Phrase + EOS Token\n",
    "MAX_PHRASE_LENGTH = 31 + 1\n",
    "# Whether to Train The model\n",
    "TRAIN_MODEL = True\n",
    "# Whether to Load Pretrained Weights\n",
    "LOAD_WEIGHTS = False\n",
    "# Learning Rate Warmup Method [log,exp]\n",
    "WARMUP_METHOD = 'exp'\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:43.906239Z",
     "iopub.execute_input": "2023-07-06T19:48:43.906620Z",
     "iopub.status.idle": "2023-07-06T19:48:43.915158Z",
     "shell.execute_reply.started": "2023-07-06T19:48:43.906589Z",
     "shell.execute_reply": "2023-07-06T19:48:43.914129Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# MatplotLib Global Settings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 24"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:43.919272Z",
     "iopub.execute_input": "2023-07-06T19:48:43.919630Z",
     "iopub.status.idle": "2023-07-06T19:48:43.930254Z",
     "shell.execute_reply.started": "2023-07-06T19:48:43.919604Z",
     "shell.execute_reply": "2023-07-06T19:48:43.929171Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Read Train DataFrame\n",
    "if DEBUG:\n",
    "    train = pd.read_csv(f'{DATA_FOLDER}/train.csv').head(5000)\n",
    "else:\n",
    "    train = pd.read_csv(f'{DATA_FOLDER}/train.csv')\n",
    "    \n",
    "# Set Train Indexed By sqeuence_id\n",
    "train_sequence_id = train.set_index('sequence_id')\n",
    "\n",
    "# Number Of Train Samples\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')\n",
    "\n",
    "display(train.info())\n",
    "display(train.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:43.933779Z",
     "iopub.execute_input": "2023-07-06T19:48:43.934085Z",
     "iopub.status.idle": "2023-07-06T19:48:44.124896Z",
     "shell.execute_reply.started": "2023-07-06T19:48:43.934048Z",
     "shell.execute_reply": "2023-07-06T19:48:44.123850Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# File Path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{DATA_FOLDER}/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:44.127717Z",
     "iopub.execute_input": "2023-07-06T19:48:44.128008Z",
     "iopub.status.idle": "2023-07-06T19:48:44.160773Z",
     "shell.execute_reply.started": "2023-07-06T19:48:44.127984Z",
     "shell.execute_reply": "2023-07-06T19:48:44.159851Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example File Paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Unique Parquet Files\n",
    "INFERENCE_FILE_PATHS = pd.Series(\n",
    "        glob.glob('train_landmark_subsets/*')\n",
    "    )\n",
    "\n",
    "print(f'Found {len(INFERENCE_FILE_PATHS)} Inference Pickle Files')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:44.162356Z",
     "iopub.execute_input": "2023-07-06T19:48:44.162727Z",
     "iopub.status.idle": "2023-07-06T19:48:44.170539Z",
     "shell.execute_reply.started": "2023-07-06T19:48:44.162694Z",
     "shell.execute_reply": "2023-07-06T19:48:44.169458Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load X/y"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Train/Validation\n",
    "if USE_VAL:\n",
    "    # TRAIN\n",
    "    X_train = np.load('X_train.npy')\n",
    "    y_train = np.load('y_train.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    # VAL\n",
    "    X_val = np.load('X_val.npy')\n",
    "    y_val = np.load('y_val.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_VAL_SAMPLES = len(X_val)\n",
    "    # Shapes\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "# Train On All Data\n",
    "else:\n",
    "    # TRAIN\n",
    "    X_train = np.load('X.npy')\n",
    "    y_train = np.load('y.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    print(f'X_train shape: {X_train.shape}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:48:44.172086Z",
     "iopub.execute_input": "2023-07-06T19:48:44.172663Z",
     "iopub.status.idle": "2023-07-06T19:49:12.800243Z",
     "shell.execute_reply.started": "2023-07-06T19:48:44.172463Z",
     "shell.execute_reply": "2023-07-06T19:49:12.799212Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Batch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Example Batch For Debugging\n",
    "N_EXAMPLE_BATCH_SAMPLES = 1024\n",
    "N_EXAMPLE_BATCH_SAMPLES_SMALL = 32\n",
    "# Example Batch\n",
    "X_batch = {\n",
    "    'frames': np.copy(X_train[:N_EXAMPLE_BATCH_SAMPLES]),\n",
    "    'phrase': np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES]),\n",
    "#     'phrase_type': np.copy(y_phrase_type_train[:N_EXAMPLE_BATCH_SAMPLES]),\n",
    "}\n",
    "y_batch = np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES])\n",
    "# Small Example Batch\n",
    "X_batch_small = {\n",
    "    'frames': np.copy(X_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),\n",
    "    'phrase': np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),\n",
    "#     'phrase_type': np.copy(y_phrase_type_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),\n",
    "}\n",
    "y_batch_small = np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:12.801889Z",
     "iopub.execute_input": "2023-07-06T19:49:12.802241Z",
     "iopub.status.idle": "2023-07-06T19:49:12.841464Z",
     "shell.execute_reply.started": "2023-07-06T19:49:12.802211Z",
     "shell.execute_reply": "2023-07-06T19:49:12.840503Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Parquet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Read First Parquet File\n",
    "# example_parquet_df = pd.read_parquet(train['file_path'][0])\n",
    "example_parquet_df = pd.read_parquet(INFERENCE_FILE_PATHS[0])\n",
    "\n",
    "# Each parquet file contains 1000 recordings\n",
    "print(f'# Unique Recording: {example_parquet_df.index.nunique()}')\n",
    "# Display DataFrame layout\n",
    "display(example_parquet_df.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:12.842980Z",
     "iopub.execute_input": "2023-07-06T19:49:12.843346Z",
     "iopub.status.idle": "2023-07-06T19:49:13.338934Z",
     "shell.execute_reply.started": "2023-07-06T19:49:12.843313Z",
     "shell.execute_reply": "2023-07-06T19:49:13.338040Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Landmark Indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Get indices in original dataframe\n",
    "def get_idxs(df, words_pos, words_neg=[], ret_names=True, idxs_pos=None):\n",
    "    idxs = []\n",
    "    names = []\n",
    "    for w in words_pos:\n",
    "        for col_idx, col in enumerate(example_parquet_df.columns):\n",
    "            # Exclude Non Landmark Columns\n",
    "            if col in ['frame']:\n",
    "                continue\n",
    "                \n",
    "            col_idx = int(col.split('_')[-1])\n",
    "            # Check if column name contains all words\n",
    "            if (w in col) and (idxs_pos is None or col_idx in idxs_pos) and all([w not in col for w in words_neg]):\n",
    "                idxs.append(col_idx)\n",
    "                names.append(col)\n",
    "    # Convert to Numpy arrays\n",
    "    idxs = np.array(idxs)\n",
    "    names = np.array(names)\n",
    "    # Returns either both column indices and names\n",
    "    if ret_names:\n",
    "        return idxs, names\n",
    "    # Or only columns indices\n",
    "    else:\n",
    "        return idxs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.340131Z",
     "iopub.execute_input": "2023-07-06T19:49:13.340502Z",
     "iopub.status.idle": "2023-07-06T19:49:13.349581Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.340475Z",
     "shell.execute_reply": "2023-07-06T19:49:13.348260Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Lips Landmark Face Ids\n",
    "LIPS_LANDMARK_IDXS = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "\n",
    "# Landmark Indices for Left/Right hand without z axis in raw data\n",
    "LEFT_HAND_IDXS0, LEFT_HAND_NAMES0 = get_idxs(example_parquet_df, ['left_hand'], ['z'])\n",
    "RIGHT_HAND_IDXS0, RIGHT_HAND_NAMES0 = get_idxs(example_parquet_df, ['right_hand'], ['z'])\n",
    "LIPS_IDXS0, LIPS_NAMES0 = get_idxs(example_parquet_df, ['face'], ['z'], idxs_pos=LIPS_LANDMARK_IDXS)\n",
    "COLUMNS0 = np.concatenate((LEFT_HAND_NAMES0, RIGHT_HAND_NAMES0, LIPS_NAMES0))\n",
    "N_COLS0 = len(COLUMNS0)\n",
    "# Only X/Y axes are used\n",
    "N_DIMS0 = 2\n",
    "\n",
    "print(f'N_COLS0: {N_COLS0}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.351450Z",
     "iopub.execute_input": "2023-07-06T19:49:13.352235Z",
     "iopub.status.idle": "2023-07-06T19:49:13.364831Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.352202Z",
     "shell.execute_reply": "2023-07-06T19:49:13.363796Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COLUMNS0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Landmark Indices in subset of dataframe with only COLUMNS selected\n",
    "LEFT_HAND_IDXS = np.argwhere(np.isin(COLUMNS0, LEFT_HAND_NAMES0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(COLUMNS0, RIGHT_HAND_NAMES0)).squeeze()\n",
    "LIPS_IDXS = np.argwhere(np.isin(COLUMNS0, LIPS_NAMES0)).squeeze()\n",
    "HAND_IDXS = np.concatenate((LEFT_HAND_IDXS, RIGHT_HAND_IDXS), axis=0)\n",
    "N_COLS = N_COLS0\n",
    "# Only X/Y axes are used\n",
    "N_DIMS = 2\n",
    "\n",
    "print(f'N_COLS: {N_COLS}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.372223Z",
     "iopub.execute_input": "2023-07-06T19:49:13.372513Z",
     "iopub.status.idle": "2023-07-06T19:49:13.384419Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.372488Z",
     "shell.execute_reply": "2023-07-06T19:49:13.383260Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Indices in processed data by axes with only dominant hand\n",
    "HAND_X_IDXS = np.array(\n",
    "        [idx for idx, name in enumerate(LEFT_HAND_NAMES0) if 'x' in name]\n",
    "    ).squeeze()\n",
    "HAND_Y_IDXS = np.array(\n",
    "        [idx for idx, name in enumerate(LEFT_HAND_NAMES0) if 'y' in name]\n",
    "    ).squeeze()\n",
    "# Names in processed data by axes\n",
    "HAND_X_NAMES = LEFT_HAND_NAMES0[HAND_X_IDXS]\n",
    "HAND_Y_NAMES = LEFT_HAND_NAMES0[HAND_Y_IDXS]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.386711Z",
     "iopub.execute_input": "2023-07-06T19:49:13.387501Z",
     "iopub.status.idle": "2023-07-06T19:49:13.394551Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.387466Z",
     "shell.execute_reply": "2023-07-06T19:49:13.393317Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mean/STD Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Mean/Standard Deviations of data used for normalizing\n",
    "MEANS = np.load('MEANS.npy').reshape(-1)\n",
    "STDS = np.load('STDS.npy').reshape(-1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.396367Z",
     "iopub.execute_input": "2023-07-06T19:49:13.396805Z",
     "iopub.status.idle": "2023-07-06T19:49:13.409992Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.396741Z",
     "shell.execute_reply": "2023-07-06T19:49:13.408910Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensorflow Preprocessing Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    Tensorflow layer to process data in TFLite\n",
    "    Data needs to be processed in the model itself, so we can not use Python\n",
    "\"\"\" \n",
    "class PreprocessLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PreprocessLayer, self).__init__()\n",
    "        self.normalisation_correction = tf.constant(\n",
    "                    # Add 0.50 to x coordinates of left hand (original right hand) and substract 0.50 of right hand (original left hand)\n",
    "                     [0.50 if 'x' in name else 0.00 for name in LEFT_HAND_NAMES0],\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "    \n",
    "    @tf.function(\n",
    "        input_signature=(tf.TensorSpec(shape=[None,N_COLS0], dtype=tf.float32),),\n",
    "    )\n",
    "    def call(self, data0, resize=True):\n",
    "        # Fill NaN Values With 0\n",
    "        data = tf.where(tf.math.is_nan(data0), 0.0, data0)\n",
    "        \n",
    "        # Hacky\n",
    "        data = data[None]\n",
    "        \n",
    "        # Empty Hand Frame Filtering\n",
    "        hands = tf.slice(data, [0,0,0], [-1, -1, 84])\n",
    "        hands = tf.abs(hands)\n",
    "        mask = tf.reduce_sum(hands, axis=2)\n",
    "        mask = tf.not_equal(mask, 0)\n",
    "        data = data[mask][None]\n",
    "        \n",
    "        # Pad Zeros\n",
    "        N_FRAMES = len(data[0])\n",
    "        if N_FRAMES < N_TARGET_FRAMES:\n",
    "            data = tf.concat((\n",
    "                data,\n",
    "                tf.zeros([1,N_TARGET_FRAMES-N_FRAMES,N_COLS], dtype=tf.float32)\n",
    "            ), axis=1)\n",
    "        # Downsample\n",
    "        data = tf.image.resize(\n",
    "            data,\n",
    "            [1, N_TARGET_FRAMES],\n",
    "            method=tf.image.ResizeMethod.BILINEAR,\n",
    "        )\n",
    "        \n",
    "        # Squeeze Batch Dimension\n",
    "        data = tf.squeeze(data, axis=[0])\n",
    "        \n",
    "        return data\n",
    "    \n",
    "preprocess_layer = PreprocessLayer()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:13.411990Z",
     "iopub.execute_input": "2023-07-06T19:49:13.412670Z",
     "iopub.status.idle": "2023-07-06T19:49:15.550077Z",
     "shell.execute_reply.started": "2023-07-06T19:49:13.412634Z",
     "shell.execute_reply": "2023-07-06T19:49:15.549002Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function To Test Preprocessing Layer\n",
    "def test_preprocess_layer():\n",
    "    demo_sequence_id = example_parquet_df.index.unique()[15]\n",
    "    demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0]\n",
    "    data = preprocess_layer(demo_raw_data)\n",
    "\n",
    "    print(f'demo_raw_data shape: {demo_raw_data.shape}')\n",
    "    print(f'data shape: {data.shape}')\n",
    "    \n",
    "    return data\n",
    "    \n",
    "if IS_INTERACTIVE:\n",
    "    data = test_preprocess_layer()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.551365Z",
     "iopub.execute_input": "2023-07-06T19:49:15.551732Z",
     "iopub.status.idle": "2023-07-06T19:49:15.559442Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.551698Z",
     "shell.execute_reply": "2023-07-06T19:49:15.558464Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Train Dataset Iterator\n",
    "def get_train_dataset(X, y, batch_size=BATCH_SIZE):\n",
    "    sample_idxs = np.arange(len(X))\n",
    "    while True:\n",
    "        # Get random indices\n",
    "        random_sample_idxs = np.random.choice(sample_idxs, batch_size)\n",
    "        \n",
    "        inputs = {\n",
    "            'frames': X[random_sample_idxs],\n",
    "            'phrase': y[random_sample_idxs],\n",
    "        }\n",
    "        outputs = y[random_sample_idxs]\n",
    "        \n",
    "        yield inputs, outputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.561082Z",
     "iopub.execute_input": "2023-07-06T19:49:15.562064Z",
     "iopub.status.idle": "2023-07-06T19:49:15.571760Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.562031Z",
     "shell.execute_reply": "2023-07-06T19:49:15.570940Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train Dataset\n",
    "train_dataset = get_train_dataset(X_train, y_train)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.572968Z",
     "iopub.execute_input": "2023-07-06T19:49:15.573948Z",
     "iopub.status.idle": "2023-07-06T19:49:15.582340Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.573916Z",
     "shell.execute_reply": "2023-07-06T19:49:15.581553Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training Steps Per Epoch\n",
    "TRAIN_STEPS_PER_EPOCH = math.ceil(N_TRAIN_SAMPLES / BATCH_SIZE)\n",
    "print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.583594Z",
     "iopub.execute_input": "2023-07-06T19:49:15.584591Z",
     "iopub.status.idle": "2023-07-06T19:49:15.594006Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.584553Z",
     "shell.execute_reply": "2023-07-06T19:49:15.592974Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Validation Set\n",
    "def get_val_dataset(X, y, batch_size=BATCH_SIZE):\n",
    "    offsets = np.arange(0, len(X), batch_size)\n",
    "    while True:\n",
    "        # Iterate over whole validation set\n",
    "        for offset in offsets:\n",
    "            inputs = {\n",
    "                'frames': X[offset:offset+batch_size],\n",
    "                'phrase': y[offset:offset+batch_size],\n",
    "            }\n",
    "            outputs = y[offset:offset+batch_size]\n",
    "\n",
    "            yield inputs, outputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.595830Z",
     "iopub.execute_input": "2023-07-06T19:49:15.596295Z",
     "iopub.status.idle": "2023-07-06T19:49:15.605121Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.596260Z",
     "shell.execute_reply": "2023-07-06T19:49:15.604150Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Validation Dataset\n",
    "if USE_VAL:\n",
    "    val_dataset = get_val_dataset(X_val, y_val)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.606639Z",
     "iopub.execute_input": "2023-07-06T19:49:15.607000Z",
     "iopub.status.idle": "2023-07-06T19:49:15.614173Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.606968Z",
     "shell.execute_reply": "2023-07-06T19:49:15.613230Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if USE_VAL:\n",
    "    N_VAL_STEPS_PER_EPOCH = math.ceil(N_VAL_SAMPLES / BATCH_SIZE)\n",
    "    print(f'N_VAL_STEPS_PER_EPOCH: {N_VAL_STEPS_PER_EPOCH}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.615348Z",
     "iopub.execute_input": "2023-07-06T19:49:15.615703Z",
     "iopub.status.idle": "2023-07-06T19:49:15.622929Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.615671Z",
     "shell.execute_reply": "2023-07-06T19:49:15.621804Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# final embedding and transformer embedding size\n",
    "UNITS_ENCODER = 96\n",
    "UNITS_DECODER = 64\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS_ENCODER = 1\n",
    "NUM_BLOCKS_DECODER = 1\n",
    "NUM_HEADS = 1\n",
    "MLP_RATIO = 2\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.00\n",
    "MLP_DROPOUT_RATIO = 0.30\n",
    "MHA_DROPOUT_RATIO = 0.20\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "GELU = tf.keras.activations.gelu"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.624674Z",
     "iopub.execute_input": "2023-07-06T19:49:15.625585Z",
     "iopub.status.idle": "2023-07-06T19:49:15.633484Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.625552Z",
     "shell.execute_reply": "2023-07-06T19:49:15.632554Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Landmark Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Embeds a landmark using fully connected layers\n",
    "class LandmarkEmbedding(tf.keras.Model):\n",
    "    def __init__(self, units, name):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.units = units\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.units],\n",
    "            initializer=INIT_ZEROS,\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.635177Z",
     "iopub.execute_input": "2023-07-06T19:49:15.635608Z",
     "iopub.status.idle": "2023-07-06T19:49:15.648017Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.635577Z",
     "shell.execute_reply": "2023-07-06T19:49:15.647012Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Creates embedding for each frame\n",
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Positional embedding for each frame index\n",
    "        self.positional_embedding = tf.Variable(\n",
    "            initial_value=tf.zeros([N_TARGET_FRAMES, UNITS_ENCODER], dtype=tf.float32),\n",
    "            trainable=True,\n",
    "            name='embedding_positional_encoder',\n",
    "        )\n",
    "        # Embedding layer for Landmarks\n",
    "        self.dominant_hand_embedding = LandmarkEmbedding(UNITS_ENCODER, 'dominant_hand')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Normalize\n",
    "        x = tf.where(\n",
    "                tf.math.equal(x, 0.0),\n",
    "                0.0,\n",
    "                (x - MEANS) / STDS,\n",
    "            )\n",
    "        # Dominant Hand\n",
    "        x = self.dominant_hand_embedding(x)\n",
    "        # Add Positional Encoding\n",
    "        x = x + self.positional_embedding\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.649641Z",
     "iopub.execute_input": "2023-07-06T19:49:15.649970Z",
     "iopub.status.idle": "2023-07-06T19:49:15.659598Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.649941Z",
     "shell.execute_reply": "2023-07-06T19:49:15.658560Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model, num_of_heads, dropout, d_out=None):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth//2, use_bias=False) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth//2, use_bias=False) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth//2, use_bias=False) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model if d_out is None else d_out, use_bias=False)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, q, k, v, attention_mask=None, training=False):\n",
    "        \n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](q)\n",
    "            K = self.wk[i](k)\n",
    "            V = self.wv[i](v)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn, axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        multi_head_attention = self.do(multi_head_attention, training=training)\n",
    "        \n",
    "        return multi_head_attention"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.661194Z",
     "iopub.execute_input": "2023-07-06T19:49:15.661632Z",
     "iopub.status.idle": "2023-07-06T19:49:15.676249Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.661602Z",
     "shell.execute_reply": "2023-07-06T19:49:15.674909Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder\n",
    "\n",
    "[source](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Encoder based on multiple transformer blocks\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Encoder, self).__init__(name='encoder')\n",
    "        self.num_blocks = num_blocks\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS_ENCODER, NUM_HEADS, MHA_DROPOUT_RATIO))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS_ENCODER * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM, use_bias=False),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS_ENCODER, kernel_initializer=INIT_HE_UNIFORM, use_bias=False),\n",
    "            ]))\n",
    "            # Optional Projection to Decoder Dimension\n",
    "            if UNITS_ENCODER != UNITS_DECODER:\n",
    "                self.dense_out = tf.keras.layers.Dense(UNITS_DECODER, kernel_initializer=INIT_GLOROT_UNIFORM, use_bias=False)\n",
    "                self.apply_dense_out = True\n",
    "            else:\n",
    "                self.apply_dense_out = False\n",
    "        \n",
    "    def call(self, x, x_inp, training=False):\n",
    "        # Attention mask to ignore missing frames\n",
    "        attention_mask = tf.where(tf.math.reduce_sum(x_inp, axis=[2]) == 0.0, 0.0, 1.0)\n",
    "        attention_mask = tf.expand_dims(attention_mask, axis=1)\n",
    "        attention_mask = tf.repeat(attention_mask, repeats=N_TARGET_FRAMES, axis=1)\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x = ln_1(x + mha(x, x, x, attention_mask=attention_mask))\n",
    "            x = ln_2(x + mlp(x))\n",
    "            \n",
    "        # Optional Projection to Decoder Dimension\n",
    "        if self.apply_dense_out:\n",
    "            x = self.dense_out(x)\n",
    "    \n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.677869Z",
     "iopub.execute_input": "2023-07-06T19:49:15.678286Z",
     "iopub.status.idle": "2023-07-06T19:49:15.692477Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.678246Z",
     "shell.execute_reply": "2023-07-06T19:49:15.691691Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Decoder based on multiple transformer blocks\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Decoder, self).__init__(name='decoder')\n",
    "        self.num_blocks = num_blocks\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.Variable(\n",
    "            initial_value=tf.zeros([N_TARGET_FRAMES, UNITS_DECODER], dtype=tf.float32),\n",
    "            trainable=True,\n",
    "            name='embedding_positional_encoder',\n",
    "        )\n",
    "        # Character Embedding\n",
    "        self.char_emb = tf.keras.layers.Embedding(N_UNIQUE_CHARACTERS, UNITS_DECODER, embeddings_initializer=INIT_ZEROS)\n",
    "        # Positional Encoder MHA\n",
    "        self.pos_emb_mha = MultiHeadAttention(UNITS_DECODER, NUM_HEADS, MHA_DROPOUT_RATIO)\n",
    "        self.pos_emb_ln = tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
    "        # First Layer Normalisation\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS_DECODER, NUM_HEADS, MHA_DROPOUT_RATIO))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS_DECODER * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM, use_bias=False),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS_DECODER, kernel_initializer=INIT_HE_UNIFORM, use_bias=False),\n",
    "            ]))\n",
    "            \n",
    "    def get_causal_attention_mask(self, B):\n",
    "        i = tf.range(N_TARGET_FRAMES)[:, tf.newaxis]\n",
    "        j = tf.range(N_TARGET_FRAMES)\n",
    "        mask = tf.cast(i >= j, dtype=tf.int32)\n",
    "        mask = tf.reshape(mask, (1, N_TARGET_FRAMES, N_TARGET_FRAMES))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(B, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        mask = tf.tile(mask, mult)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        return mask\n",
    "        \n",
    "    def call(self, encoder_outputs, phrase, training=False):\n",
    "        # Batch Size\n",
    "        B = tf.shape(encoder_outputs)[0]\n",
    "        # Cast to INT32\n",
    "        phrase = tf.cast(phrase, tf.int32)\n",
    "        # Prepend SOS Token\n",
    "        phrase = tf.pad(phrase, [[0,0], [1,0]], constant_values=SOS_TOKEN, name='prepend_sos_token')\n",
    "        # Pad With PAD Token\n",
    "        phrase = tf.pad(phrase, [[0,0], [0,N_TARGET_FRAMES-MAX_PHRASE_LENGTH-1]], constant_values=PAD_TOKEN, name='append_pad_token')\n",
    "        # Causal Mask\n",
    "        causal_mask = self.get_causal_attention_mask(B)\n",
    "        # Positional Embedding\n",
    "        x = self.positional_embedding + self.char_emb(phrase)\n",
    "        # Causal Attention\n",
    "        x = self.pos_emb_ln(x + self.pos_emb_mha(x, x, x, attention_mask=causal_mask))\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x = ln_1(x + mha(x, encoder_outputs, encoder_outputs, attention_mask=causal_mask))\n",
    "            x = ln_2(x + mlp(x))\n",
    "        # Slice 31 Characters\n",
    "        x = tf.slice(x, [0, 0, 0], [-1, MAX_PHRASE_LENGTH, -1])\n",
    "    \n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.693859Z",
     "iopub.execute_input": "2023-07-06T19:49:15.694541Z",
     "iopub.status.idle": "2023-07-06T19:49:15.713425Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.694489Z",
     "shell.execute_reply": "2023-07-06T19:49:15.712564Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Causal Attention to make decoder not attent to future characters which it needs to predict\n",
    "def get_causal_attention_mask(B):\n",
    "    i = tf.range(N_TARGET_FRAMES)[:, tf.newaxis]\n",
    "    j = tf.range(N_TARGET_FRAMES)\n",
    "    mask = tf.cast(i >= j, dtype=tf.int32)\n",
    "    mask = tf.reshape(mask, (1, N_TARGET_FRAMES, N_TARGET_FRAMES))\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(B, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "        axis=0,\n",
    "    )\n",
    "    mask = tf.tile(mask, mult)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return mask\n",
    "\n",
    "get_causal_attention_mask(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.716066Z",
     "iopub.execute_input": "2023-07-06T19:49:15.716348Z",
     "iopub.status.idle": "2023-07-06T19:49:15.787288Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.716315Z",
     "shell.execute_reply": "2023-07-06T19:49:15.786315Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non Pad/SOS/EOS Token Accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# TopK accuracy for multi dimensional output\n",
    "class TopKAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, k, **kwargs):\n",
    "        super(TopKAccuracy, self).__init__(name=f'top{k}acc', **kwargs)\n",
    "        self.top_k_acc = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=k)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1, N_UNIQUE_CHARACTERS])\n",
    "        character_idxs = tf.where(y_true < N_UNIQUE_CHARACTERS0)\n",
    "        y_true = tf.gather(y_true, character_idxs, axis=0)\n",
    "        y_pred = tf.gather(y_pred, character_idxs, axis=0)\n",
    "        self.top_k_acc.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        return self.top_k_acc.result()\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.top_k_acc.reset_state()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.788772Z",
     "iopub.execute_input": "2023-07-06T19:49:15.789100Z",
     "iopub.status.idle": "2023-07-06T19:49:15.799060Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.789070Z",
     "shell.execute_reply": "2023-07-06T19:49:15.796863Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss Weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Initial Loss Weights All Set To 1\n",
    "loss_weights = np.ones(N_UNIQUE_CHARACTERS, dtype=np.float32)\n",
    "# Set Loss Weight Of Pad Token To 0\n",
    "loss_weights[PAD_TOKEN] = 0"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.800494Z",
     "iopub.execute_input": "2023-07-06T19:49:15.801136Z",
     "iopub.status.idle": "2023-07-06T19:49:15.808051Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.801105Z",
     "shell.execute_reply": "2023-07-06T19:49:15.807061Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sparse Categorical Crossentropy With Label SmoothingÂ¶"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# source:: https://stackoverflow.com/questions/60689185/label-smoothing-for-sparse-categorical-crossentropy\n",
    "def scce_with_ls(y_true, y_pred):\n",
    "    # Filter Pad Tokens\n",
    "    idxs = tf.where(y_true != PAD_TOKEN)\n",
    "    y_true = tf.gather_nd(y_true, idxs)\n",
    "    y_pred = tf.gather_nd(y_pred, idxs)\n",
    "    # One Hot Encode Sparsely Encoded Target Sign\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_true = tf.one_hot(y_true, N_UNIQUE_CHARACTERS, axis=1)\n",
    "    # Categorical Crossentropy with native label smoothing support\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing=0.25, from_logits=True)\n",
    "    loss = tf.math.reduce_mean(loss)\n",
    "    return loss"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.809652Z",
     "iopub.execute_input": "2023-07-06T19:49:15.810353Z",
     "iopub.status.idle": "2023-07-06T19:49:15.819475Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.810320Z",
     "shell.execute_reply": "2023-07-06T19:49:15.818730Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames_inp = tf.keras.layers.Input([N_TARGET_FRAMES, N_COLS], dtype=tf.float32, name='frames')\n",
    "    phrase_inp = tf.keras.layers.Input([MAX_PHRASE_LENGTH], dtype=tf.int32, name='phrase')\n",
    "    # Frames\n",
    "    x = frames_inp\n",
    "\n",
    "    # Masking\n",
    "    x = tf.keras.layers.Masking(mask_value=0.0, input_shape=(N_TARGET_FRAMES, N_COLS))(x)\n",
    "    \n",
    "    # Embedding\n",
    "    x = Embedding()(x)\n",
    "    \n",
    "    # Encoder Transformer Blocks\n",
    "    x = Encoder(NUM_BLOCKS_ENCODER)(x, frames_inp)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Decoder(NUM_BLOCKS_DECODER)(x, phrase_inp)\n",
    "    \n",
    "    # Classifier\n",
    "    x = tf.keras.Sequential([\n",
    "        # Dropout\n",
    "        tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO),\n",
    "        # Output Neurons\n",
    "        tf.keras.layers.Dense(N_UNIQUE_CHARACTERS, activation=tf.keras.activations.linear, kernel_initializer=INIT_HE_UNIFORM, use_bias=False),\n",
    "    ], name='classifier')(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames_inp, phrase_inp], outputs=outputs)\n",
    "    \n",
    "    # Categorical Crossentropy Loss With Label Smoothing\n",
    "    loss = scce_with_ls\n",
    "    \n",
    "    # Adam Optimizer\n",
    "    optimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4)\n",
    "    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n",
    "\n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        TopKAccuracy(1),\n",
    "        TopKAccuracy(5)\n",
    "    ]\n",
    "    \n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss_weights=loss_weights,\n",
    "    )\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.821685Z",
     "iopub.execute_input": "2023-07-06T19:49:15.824007Z",
     "iopub.status.idle": "2023-07-06T19:49:15.840500Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.823974Z",
     "shell.execute_reply": "2023-07-06T19:49:15.839479Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Input data\n",
    "for k, v in X_batch.items():\n",
    "    print(f'{k}: {v.shape}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.843763Z",
     "iopub.execute_input": "2023-07-06T19:49:15.844050Z",
     "iopub.status.idle": "2023-07-06T19:49:15.855086Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.844026Z",
     "shell.execute_reply": "2023-07-06T19:49:15.853719Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:15.856972Z",
     "iopub.execute_input": "2023-07-06T19:49:15.857448Z",
     "iopub.status.idle": "2023-07-06T19:49:18.876373Z",
     "shell.execute_reply.started": "2023-07-06T19:49:15.857415Z",
     "shell.execute_reply": "2023-07-06T19:49:18.875270Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot model summary\n",
    "model.summary(expand_nested=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:18.877994Z",
     "iopub.execute_input": "2023-07-06T19:49:18.878337Z",
     "iopub.status.idle": "2023-07-06T19:49:19.020220Z",
     "shell.execute_reply.started": "2023-07-06T19:49:18.878306Z",
     "shell.execute_reply": "2023-07-06T19:49:19.019456Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Model Architecture\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:19.021551Z",
     "iopub.execute_input": "2023-07-06T19:49:19.021893Z",
     "iopub.status.idle": "2023-07-06T19:49:19.264751Z",
     "shell.execute_reply.started": "2023-07-06T19:49:19.021860Z",
     "shell.execute_reply": "2023-07-06T19:49:19.263782Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verify Training Flag"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def verify_correct_training_flag():\n",
    "    # Verify static output for inference\n",
    "    pred = model(X_batch_small, training=False)\n",
    "    for _ in tqdm(range(10)):\n",
    "        assert tf.reduce_min(tf.cast(pred == model(X_batch_small, training=False), tf.int8)) == 1\n",
    "\n",
    "    # Verify at least 99% varying output due to dropout during training\n",
    "    for _ in tqdm(range(10)):\n",
    "        assert tf.reduce_mean(tf.cast(pred != model(X_batch_small, training=True), tf.float32)) > 0.99\n",
    "        \n",
    "verify_correct_training_flag()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:19.266137Z",
     "iopub.execute_input": "2023-07-06T19:49:19.266507Z",
     "iopub.status.idle": "2023-07-06T19:49:24.947235Z",
     "shell.execute_reply.started": "2023-07-06T19:49:19.266474Z",
     "shell.execute_reply": "2023-07-06T19:49:24.946217Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verify No NaN Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify No NaN predictions\n",
    "def verify_no_nan_predictions():\n",
    "    y_pred = model.predict(\n",
    "        val_dataset if USE_VAL else train_dataset,\n",
    "        steps=N_VAL_STEPS_PER_EPOCH if USE_VAL else 100,\n",
    "        verbose=VERBOSE,\n",
    "    )\n",
    "\n",
    "    print(f'# NaN Values In Predictions: {np.isnan(y_pred).sum()}')\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(f'Logit Predictions Initialized Model')\n",
    "    pd.Series(y_pred.flatten()).plot(kind='hist', bins=128)\n",
    "    plt.xlabel('Logits')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "verify_no_nan_predictions()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:24.956258Z",
     "iopub.execute_input": "2023-07-06T19:49:24.956803Z",
     "iopub.status.idle": "2023-07-06T19:49:32.833261Z",
     "shell.execute_reply.started": "2023-07-06T19:49:24.956770Z",
     "shell.execute_reply": "2023-07-06T19:49:32.832335Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning Rate Scheduler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if WARMUP_METHOD == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:32.834944Z",
     "iopub.execute_input": "2023-07-06T19:49:32.835334Z",
     "iopub.status.idle": "2023-07-06T19:49:32.842428Z",
     "shell.execute_reply.started": "2023-07-06T19:49:32.835301Z",
     "shell.execute_reply": "2023-07-06T19:49:32.841401Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "    \n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "    \n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "    \n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n",
    "# Plot Learning Rate Schedule\n",
    "plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(f'log_transformer.csv')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:32.844033Z",
     "iopub.execute_input": "2023-07-06T19:49:32.844390Z",
     "iopub.status.idle": "2023-07-06T19:49:33.735302Z",
     "shell.execute_reply.started": "2023-07-06T19:49:32.844358Z",
     "shell.execute_reply": "2023-07-06T19:49:33.734440Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weight Decay Callback"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=WD_RATIO):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:33.736772Z",
     "iopub.execute_input": "2023-07-06T19:49:33.737742Z",
     "iopub.status.idle": "2023-07-06T19:49:33.744511Z",
     "shell.execute_reply.started": "2023-07-06T19:49:33.737709Z",
     "shell.execute_reply": "2023-07-06T19:49:33.743335Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Initialized Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "## Evaluate Initialized Model On Validation Data\n",
    "y_pred = model.evaluate(\n",
    "    val_dataset if USE_VAL else train_dataset,\n",
    "    steps=N_VAL_STEPS_PER_EPOCH if USE_VAL else TRAIN_STEPS_PER_EPOCH,\n",
    "    verbose='auto',\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:49:33.746005Z",
     "iopub.execute_input": "2023-07-06T19:49:33.746379Z",
     "iopub.status.idle": "2023-07-06T19:50:13.696494Z",
     "shell.execute_reply.started": "2023-07-06T19:49:33.746343Z",
     "shell.execute_reply": "2023-07-06T19:50:13.695566Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# baseline accuracy when only pad token is predicted\n",
    "if USE_VAL:\n",
    "    baseline_accuracy = np.mean(y_val == PAD_TOKEN)\n",
    "else:\n",
    "    baseline_accuracy = np.mean(y_train == PAD_TOKEN)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.4f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:50:13.698255Z",
     "iopub.execute_input": "2023-07-06T19:50:13.698641Z",
     "iopub.status.idle": "2023-07-06T19:50:13.712324Z",
     "shell.execute_reply.started": "2023-07-06T19:50:13.698608Z",
     "shell.execute_reply": "2023-07-06T19:50:13.711056Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gc.collect()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:50:13.714007Z",
     "iopub.execute_input": "2023-07-06T19:50:13.714370Z",
     "iopub.status.idle": "2023-07-06T19:50:13.981018Z",
     "shell.execute_reply.started": "2023-07-06T19:50:13.714337Z",
     "shell.execute_reply": "2023-07-06T19:50:13.979943Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRAIN_MODEL:\n",
    "    # Clear all models in GPU\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Get new fresh model\n",
    "    model = get_model()\n",
    "\n",
    "    # Sanity Check\n",
    "    model.summary()\n",
    "\n",
    "    # Actual Training\n",
    "    history = model.fit(\n",
    "            x=train_dataset,\n",
    "            steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "            epochs=N_EPOCHS,\n",
    "            # Only used for validation data since training data is a generator\n",
    "            validation_data=val_dataset if USE_VAL else None,\n",
    "            validation_steps=N_VAL_STEPS_PER_EPOCH if USE_VAL else None,\n",
    "            callbacks=[\n",
    "                lr_callback,\n",
    "                WeightDecayCallback(),\n",
    "                csv_logger\n",
    "            ],\n",
    "            verbose = 'auto',\n",
    "        )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T19:50:13.982530Z",
     "iopub.execute_input": "2023-07-06T19:50:13.983707Z",
     "iopub.status.idle": "2023-07-06T21:37:16.055354Z",
     "shell.execute_reply.started": "2023-07-06T19:50:13.983669Z",
     "shell.execute_reply": "2023-07-06T21:37:16.054285Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Weights\n",
    "if LOAD_WEIGHTS:\n",
    "    model.load_weights('/kaggle/input/aslfr-training-python37/model.h5')\n",
    "    print(f'Successfully Loaded Pretrained Weights')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:16.057207Z",
     "iopub.execute_input": "2023-07-06T21:37:16.057613Z",
     "iopub.status.idle": "2023-07-06T21:37:16.062994Z",
     "shell.execute_reply.started": "2023-07-06T21:37:16.057579Z",
     "shell.execute_reply": "2023-07-06T21:37:16.061846Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save Model Weights\n",
    "model.save_weights('model_2.h5')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:16.064538Z",
     "iopub.execute_input": "2023-07-06T21:37:16.064986Z",
     "iopub.status.idle": "2023-07-06T21:37:16.220432Z",
     "shell.execute_reply.started": "2023-07-06T21:37:16.064954Z",
     "shell.execute_reply": "2023-07-06T21:37:16.219230Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify Model is Loaded Correctly\n",
    "model.evaluate(\n",
    "    val_dataset if USE_VAL else train_dataset,\n",
    "    steps=N_VAL_STEPS_PER_EPOCH if USE_VAL else TRAIN_STEPS_PER_EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose='auto',\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:16.224423Z",
     "iopub.execute_input": "2023-07-06T21:37:16.224802Z",
     "iopub.status.idle": "2023-07-06T21:37:59.779709Z",
     "shell.execute_reply.started": "2023-07-06T21:37:16.224776Z",
     "shell.execute_reply": "2023-07-06T21:37:59.778511Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Levenshtein Distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Output Predictions to string\n",
    "def outputs2phrase(outputs):\n",
    "    if outputs.ndim == 2:\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "    \n",
    "    return ''.join([ORD2CHAR.get(s, '') for s in outputs])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:59.780935Z",
     "iopub.execute_input": "2023-07-06T21:37:59.781225Z",
     "iopub.status.idle": "2023-07-06T21:37:59.788568Z",
     "shell.execute_reply.started": "2023-07-06T21:37:59.781201Z",
     "shell.execute_reply": "2023-07-06T21:37:59.787588Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@tf.function()\n",
    "def predict_phrase(frames):\n",
    "    # Add Batch Dimension\n",
    "    frames = tf.expand_dims(frames, axis=0)\n",
    "    # Start Phrase\n",
    "    phrase = tf.fill([1,MAX_PHRASE_LENGTH], PAD_TOKEN)\n",
    "\n",
    "    for idx in tf.range(MAX_PHRASE_LENGTH):\n",
    "        # Cast phrase to int8\n",
    "        phrase = tf.cast(phrase, tf.int8)\n",
    "        # Predict Next Token\n",
    "        outputs = model({\n",
    "            'frames': frames,\n",
    "            'phrase': phrase,\n",
    "        })\n",
    "\n",
    "        # Add predicted token to input phrase\n",
    "        phrase = tf.cast(phrase, tf.int32)\n",
    "        phrase = tf.where(\n",
    "            tf.range(MAX_PHRASE_LENGTH) < idx + 1,\n",
    "            tf.argmax(outputs, axis=2, output_type=tf.int32),\n",
    "            phrase,\n",
    "        )\n",
    "\n",
    "    # Squeeze outputs\n",
    "    outputs = tf.squeeze(phrase, axis=0)\n",
    "    outputs = tf.one_hot(outputs, N_UNIQUE_CHARACTERS)\n",
    "\n",
    "    # Return a dictionary with the output tensor\n",
    "    return outputs\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:59.789937Z",
     "iopub.execute_input": "2023-07-06T21:37:59.790492Z",
     "iopub.status.idle": "2023-07-06T21:37:59.801709Z",
     "shell.execute_reply.started": "2023-07-06T21:37:59.790460Z",
     "shell.execute_reply": "2023-07-06T21:37:59.800651Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Levenstein Distance Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute Levenstein Distances\n",
    "def get_ld_train():\n",
    "    N = 100 if IS_INTERACTIVE else 1000\n",
    "    LD_TRAIN = []\n",
    "    for idx, (frames, phrase_true) in enumerate(zip(tqdm(X_train, total=N), y_train)):\n",
    "        # Predict Phrase and Convert to String\n",
    "        phrase_pred = predict_phrase(frames).numpy()\n",
    "        phrase_pred = outputs2phrase(phrase_pred)\n",
    "        # True Phrase Ordinal to String\n",
    "        phrase_true = outputs2phrase(phrase_true)\n",
    "        # Add Levenstein Distance\n",
    "        LD_TRAIN.append({\n",
    "            'phrase_true': phrase_true,\n",
    "            'phrase_pred': phrase_pred,\n",
    "            'levenshtein_distance': levenshtein(phrase_pred, phrase_true),\n",
    "        })\n",
    "        # Take subset in interactive mode\n",
    "        if idx == N:\n",
    "            break\n",
    "            \n",
    "    # Convert to DataFrame\n",
    "    LD_TRAIN_DF = pd.DataFrame(LD_TRAIN)\n",
    "    \n",
    "    return LD_TRAIN_DF"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:59.804858Z",
     "iopub.execute_input": "2023-07-06T21:37:59.805209Z",
     "iopub.status.idle": "2023-07-06T21:37:59.813465Z",
     "shell.execute_reply.started": "2023-07-06T21:37:59.805174Z",
     "shell.execute_reply": "2023-07-06T21:37:59.812578Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LD_TRAIN_DF = get_ld_train()\n",
    "\n",
    "# Display Errors\n",
    "display(LD_TRAIN_DF.head(30))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:37:59.814801Z",
     "iopub.execute_input": "2023-07-06T21:37:59.815247Z",
     "iopub.status.idle": "2023-07-06T21:40:05.493721Z",
     "shell.execute_reply.started": "2023-07-06T21:37:59.815217Z",
     "shell.execute_reply": "2023-07-06T21:40:05.492575Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Value Counts\n",
    "LD_TRAIN_VC = dict([(i, 0) for i in range(LD_TRAIN_DF['levenshtein_distance'].max()+1)])\n",
    "for ld in LD_TRAIN_DF['levenshtein_distance']:\n",
    "    LD_TRAIN_VC[ld] += 1\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "pd.Series(LD_TRAIN_VC).plot(kind='bar', width=1)\n",
    "plt.title(f'Train Levenstein Distance Distribution | Mean: {LD_TRAIN_DF.levenshtein_distance.mean():.4f}')\n",
    "plt.xlabel('Levenstein Distance')\n",
    "plt.ylabel('Sample Count')\n",
    "plt.xlim(-0.50, LD_TRAIN_DF.levenshtein_distance.max()+0.50)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('temp.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:05.495443Z",
     "iopub.execute_input": "2023-07-06T21:40:05.496119Z",
     "iopub.status.idle": "2023-07-06T21:40:06.155454Z",
     "shell.execute_reply.started": "2023-07-06T21:40:05.496084Z",
     "shell.execute_reply": "2023-07-06T21:40:06.154536Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Levenstein Distance Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute Levenstein Distances\n",
    "def get_ld_val():\n",
    "    N = 100 if IS_INTERACTIVE else 1000\n",
    "    LD_VAL = []\n",
    "    for idx, (frames, phrase_true) in enumerate(zip(tqdm(X_val, total=N), y_val)):\n",
    "        # Predict Phrase and Convert to String\n",
    "        phrase_pred = predict_phrase(frames).numpy()\n",
    "        phrase_pred = outputs2phrase(phrase_pred)\n",
    "        # True Phrase Ordinal to String\n",
    "        phrase_true = outputs2phrase(phrase_true)\n",
    "        # Add Levenstein Distance\n",
    "        LD_VAL.append({\n",
    "            'phrase_true': phrase_true,\n",
    "            'phrase_pred': phrase_pred,\n",
    "            'levenshtein_distance': levenshtein(phrase_pred, phrase_true),\n",
    "        })\n",
    "        # Take subset in interactive mode\n",
    "        if idx == N:\n",
    "            break\n",
    "            \n",
    "    # Convert to DataFrame\n",
    "    LD_VAL_DF = pd.DataFrame(LD_VAL)\n",
    "    \n",
    "    return LD_VAL_DF"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.156951Z",
     "iopub.execute_input": "2023-07-06T21:40:06.157594Z",
     "iopub.status.idle": "2023-07-06T21:40:06.166298Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.157558Z",
     "shell.execute_reply": "2023-07-06T21:40:06.164562Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if USE_VAL:\n",
    "    LD_VAL_DF = get_ld_val()\n",
    "\n",
    "    # Display Errors\n",
    "    display(LD_VAL_DF.head(30))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.168404Z",
     "iopub.execute_input": "2023-07-06T21:40:06.169359Z",
     "iopub.status.idle": "2023-07-06T21:40:06.178226Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.169326Z",
     "shell.execute_reply": "2023-07-06T21:40:06.177277Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Value Counts\n",
    "if USE_VAL:\n",
    "    LD_VAL_VC = dict([(i, 0) for i in range(LD_VAL_DF['levenshtein_distance'].max()+1)])\n",
    "    for ld in LD_VAL_DF['levenshtein_distance']:\n",
    "        LD_VAL_VC[ld] += 1\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    pd.Series(LD_VAL_VC).plot(kind='bar', width=1)\n",
    "    plt.title(f'Validation Levenstein Distance Distribution | Mean: {LD_VAL_DF.levenshtein_distance.mean():.4f}')\n",
    "    plt.xlabel('Levenstein Distance')\n",
    "    plt.ylabel('Sample Count')\n",
    "    plt.xlim(0-0.50, LD_VAL_DF.levenshtein_distance.max()+0.50)\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig('temp.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.179581Z",
     "iopub.execute_input": "2023-07-06T21:40:06.180028Z",
     "iopub.status.idle": "2023-07-06T21:40:06.190712Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.179995Z",
     "shell.execute_reply": "2023-07-06T21:40:06.189790Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training History"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n",
    "    # Only plot when training\n",
    "    if not TRAIN_MODEL:\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    values = history.history[metric]\n",
    "    N_EPOCHS = len(values)\n",
    "    val = 'val' in ''.join(history.history.keys())\n",
    "    # Epoch Ticks\n",
    "    if N_EPOCHS <= 20:\n",
    "        x = np.arange(1, N_EPOCHS + 1)\n",
    "    else:\n",
    "        x = [1, 5] + [10 + 5 * idx for idx in range((N_EPOCHS - 10) // 5 + 1)]\n",
    "\n",
    "    x_ticks = np.arange(1, N_EPOCHS+1)\n",
    "\n",
    "    # Validation\n",
    "    if val:\n",
    "        val_values = history.history[f'val_{metric}']\n",
    "        val_argmin = f_best(val_values)\n",
    "        plt.plot(x_ticks, val_values, label=f'val')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(x_ticks, values, label=f'train')\n",
    "    argmin = f_best(values)\n",
    "    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n",
    "    if val:\n",
    "        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n",
    "\n",
    "    plt.title(f'Model {metric}', fontsize=24, pad=10)\n",
    "    plt.ylabel(metric, fontsize=20, labelpad=10)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if yscale is not None:\n",
    "        plt.yscale(yscale)\n",
    "        \n",
    "    if yticks is not None:\n",
    "        plt.yticks(yticks, fontsize=16)\n",
    "\n",
    "    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.grid()\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.192690Z",
     "iopub.execute_input": "2023-07-06T21:40:06.193411Z",
     "iopub.status.idle": "2023-07-06T21:40:06.206435Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.193379Z",
     "shell.execute_reply": "2023-07-06T21:40:06.205569Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_history_metric('loss', f_best=np.argmin)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.209382Z",
     "iopub.execute_input": "2023-07-06T21:40:06.210100Z",
     "iopub.status.idle": "2023-07-06T21:40:06.638090Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.210067Z",
     "shell.execute_reply": "2023-07-06T21:40:06.637131Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_history_metric('top1acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:06.639559Z",
     "iopub.execute_input": "2023-07-06T21:40:06.640396Z",
     "iopub.status.idle": "2023-07-06T21:40:07.072246Z",
     "shell.execute_reply.started": "2023-07-06T21:40:06.640360Z",
     "shell.execute_reply": "2023-07-06T21:40:07.070666Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_history_metric('top5acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:07.074375Z",
     "iopub.execute_input": "2023-07-06T21:40:07.075110Z",
     "iopub.status.idle": "2023-07-06T21:40:07.495476Z",
     "shell.execute_reply.started": "2023-07-06T21:40:07.075074Z",
     "shell.execute_reply": "2023-07-06T21:40:07.494465Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Model Layer Names\n",
    "for l in model.layers:\n",
    "    print(l.name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:07.497380Z",
     "iopub.execute_input": "2023-07-06T21:40:07.497750Z",
     "iopub.status.idle": "2023-07-06T21:40:07.503357Z",
     "shell.execute_reply.started": "2023-07-06T21:40:07.497709Z",
     "shell.execute_reply": "2023-07-06T21:40:07.502359Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COLUMNS0.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def encoder(self, x, frames_inp):\n",
    "        x = self.model.get_layer('embedding')(x)\n",
    "        x = self.model.get_layer('encoder')(x, frames_inp)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    @tf.function(jit_compile=True)\n",
    "    def decoder(self, x, phrase_inp):\n",
    "        x = self.model.get_layer('decoder')(x, phrase_inp)\n",
    "        x = self.model.get_layer('classifier')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, N_COLS0], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        # Number Of Input Frames\n",
    "        N_INPUT_FRAMES = tf.shape(inputs)[0]\n",
    "        # Preprocess Data\n",
    "        frames_inp = self.preprocess_layer(inputs)        \n",
    "        # Add Batch Dimension\n",
    "        frames_inp = tf.expand_dims(frames_inp, axis=0)\n",
    "        # Get Encoding\n",
    "        encoding = self.encoder(frames_inp, frames_inp)\n",
    "        # Make Prediction\n",
    "        phrase = tf.fill([1,MAX_PHRASE_LENGTH], PAD_TOKEN)\n",
    "        # Predict One Token At A Time\n",
    "        stop = False\n",
    "        for idx in tf.range(MAX_PHRASE_LENGTH):\n",
    "            # Cast phrase to int8\n",
    "            phrase = tf.cast(phrase, tf.int8)\n",
    "            # If EOS token is predicted, stop predicting\n",
    "            outputs = tf.cond(\n",
    "                stop,\n",
    "                lambda: tf.one_hot(tf.cast(phrase, tf.int32), N_UNIQUE_CHARACTERS),\n",
    "                lambda: self.decoder(encoding, phrase)\n",
    "            )\n",
    "            # Add predicted token to input phrase\n",
    "            phrase = tf.cast(phrase, tf.int32)\n",
    "            # Replcae PAD token with predicted token up to idx\n",
    "            phrase = tf.where(\n",
    "                tf.range(MAX_PHRASE_LENGTH) < idx + 1,\n",
    "                tf.argmax(outputs, axis=2, output_type=tf.int32),\n",
    "                phrase,\n",
    "            )\n",
    "            # Predicted Token\n",
    "            predicted_token = phrase[0,idx]\n",
    "            # If EOS (End Of Sentence) token is predicted stop\n",
    "            if not stop:\n",
    "                stop = predicted_token == EOS_TOKEN\n",
    "            \n",
    "        # Squeeze outputs\n",
    "        outputs = tf.squeeze(phrase, axis=0)\n",
    "        outputs = tf.one_hot(outputs, N_UNIQUE_CHARACTERS)\n",
    "            \n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs }\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n",
    "\n",
    "# Sanity Check\n",
    "# demo_sequence_id = 1816796431\n",
    "demo_sequence_id = example_parquet_df.index.unique()[0]\n",
    "print(f'demo_sequence_id: {demo_sequence_id}')\n",
    "demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0].values\n",
    "demo_phrase_true = train_sequence_id.loc[demo_sequence_id, 'phrase']\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)['outputs'].numpy()\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "print(f'demo_outputs phrase decoded: {outputs2phrase(demo_output)}')\n",
    "print(f'phrase true: {demo_phrase_true}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:07.505008Z",
     "iopub.execute_input": "2023-07-06T21:40:07.505712Z",
     "iopub.status.idle": "2023-07-06T21:40:13.850801Z",
     "shell.execute_reply.started": "2023-07-06T21:40:07.505680Z",
     "shell.execute_reply": "2023-07-06T21:40:13.849671Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_parquet_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open('model_save/model_2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:40:13.852237Z",
     "iopub.execute_input": "2023-07-06T21:40:13.853796Z",
     "iopub.status.idle": "2023-07-06T21:41:18.851077Z",
     "shell.execute_reply.started": "2023-07-06T21:40:13.853759Z",
     "shell.execute_reply": "2023-07-06T21:41:18.849698Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Add selected_columns json to only select specific columns from input frames\n",
    "with open('inference_args.json', 'w') as f:\n",
    "     json.dump({ 'selected_columns': COLUMNS0.tolist() }, f)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:41:18.854712Z",
     "iopub.execute_input": "2023-07-06T21:41:18.855066Z",
     "iopub.status.idle": "2023-07-06T21:41:18.860402Z",
     "shell.execute_reply.started": "2023-07-06T21:41:18.855037Z",
     "shell.execute_reply": "2023-07-06T21:41:18.859294Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Zip Model\n",
    "!zip submission.zip /kaggle/working/model.tflite /kaggle/working/inference_args.json"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T21:41:18.861920Z",
     "iopub.execute_input": "2023-07-06T21:41:18.862553Z",
     "iopub.status.idle": "2023-07-06T21:41:20.828749Z",
     "shell.execute_reply.started": "2023-07-06T21:41:18.862504Z",
     "shell.execute_reply": "2023-07-06T21:41:20.827591Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
